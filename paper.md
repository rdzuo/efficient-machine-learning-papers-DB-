## SIGMOD 
### 2023

#### ST4ML: Machine Learning Oriented Spatio-Temporal Data Processing at Scale  
Kaiqi Liu (Nanyang Technological University)*; Panrong Tong (Alibaba Group); Mo Li (Nanyang Technological University); Yue Wu (Damo Academy, Alibaba Group); Jianqiang Huang (Alibaba Group)

#### FlexMoE: Scaling Large-scale Sparse Pre-trained Model Training via Dynamic Device Placement
Xiaonan Nie (Peking University)*; Xupeng Miao (Carnegie Mellon University); Zilong Wang (Microsoft); Zichao Yang (Carnegie Mellon University); Jilong Xue (Microsoft Research); Lingxiao Ma (Microsoft Research); Gang Cao (BAAI); Bin Cui (Peking University)

#### Automating and Optimizing Data-Centric What-If Analyses on Native Machine Learning Pipelines  
Stefan Grafberger (University of Amsterdam); Paul Groth (University of Amsterdam); Sebastian Schelter (University of Amsterdam);

#### GoodCore: Coreset Selection over Incomplete Data for Data-effective and Data-efficient Machine Learning  
Chengliang Chai (Beijing Institute of Technology); Jiabin Liu (Tsinghua University); Nan Tang (Qatar Computing Research Institute, HBKU); Ju Fan (Renmin University of China); dongjing miao (哈尔滨工业大学); Jiayi Wang (Tsinghua University); Yuyu Luo (Tsinghua University); Guoliang Li (Tsinghua University);

#### Scalable and Efficient Full-Graph GNN Training for Large Graphs  
Xinchen Wan (HKUST); Kaiqiang Xu (HKUST); Xudong Liao (HKUST); Yilun Jin (The Hong Kong University of Science and Technology); Kai Chen (HKUST); Xin Jin (Peking University);

#### DeltaBoost: Gradient Boosting Decision Trees with Efficient Machine Unlearning
Zhaomin Wu (National University of Singapore); Junhui Zhu (National University of Singapore); Qinbin Li (National University of Singapore); Bingsheng He (National University of Singapore);

#### DUCATI: A Dual-Cache Training System for Graph Neural Networks on Giant Graphs with GPU  
Xin Zhang (Hong Kong University of Science and Technology); Yanyan Shen (Shanghai Jiao Tong University); Yingxia Shao (BUPT); Lei Chen (Hong Kong University of Science and Technology);

#### Caerus: A Caching-based Framework for Scalable Temporal Graph Neural Networks  
Yiming Li (Hong Kong University of Science and Technology)*; Yanyan Shen (Shanghai Jiao Tong University); Lei Chen (Hong Kong University of Science and Technology); Mingxuan Yuan (Huawei)

#### EARLY: Efficient and Reliable Graph Neural Network for Dynamic Graphs  
Haoyang Li (The Hong Kong University of Science and Technology); Lei Chen (Hong Kong University of Science and Technology);

#### FEC: Efficient Deep Recommendation Model Training with Flexible Embedding Communication  
Kaihao Ma ( The Chinese University of Hong Kong); Xiao Yan (Southern University of Science and Technology)*; Zhenkun Cai (The Chinese University of Hong Kong); Yuzhen Huang (Meta); Yidi Wu (Meta Platforms, Inc); James Cheng (CUHK)

### 2022

#### Nautilus: An Optimized System for Deep Transfer Learning over Evolving Training Datasets  
Supun C Nakandala (University of California, San Diego)*; Arun Kumar (University of California, San Diego)

#### Where Is My Training Bottleneck? Hidden Trade-Offs in Deep Learning Preprocessing Pipelines  
Alexander Isenko (Technical University of Munich)*; Ruben Mayer (Technical University of Munich); Jeffery Jedele (Technical University of Munich); Hans-Arno Jacobsen (University of Toronto)

#### Complaint-Driven Training Data Debugging at Interactive Speeds  
Lampros Flokas (Columbia University)*; Weiyuan Wu (Simon Fraser University); Yejia Liu (Simon Fraser University); Jiannan Wang (Simon Fraser University); Nakul Verma (Columbia University); Eugene Wu (Columbia University)


#### HET-GMP: a Graph-based System Approach to Scaling Large Embedding Model Training  
Xupeng Miao (Peking University)*; Yining Shi (Peking University); Hailin Zhang (Peking University); Xin Zhang (Peking University); Xiaonan Nie (Peking University); Zhi Yang (Peking University); Bin Cui (Peking University)

#### Camel: Managing Data for Efficient Stream Learning  
Yiming Li (Hong Kong University of Science and Technology)*; Yanyan Shen (Shanghai Jiao Tong University); Lei Chen (Hong Kong University of Science and Technology)

#### In-Database Machine Learning with CorgiPile: Stochastic Gradient Descent without Full Data Shuffle  
Lijie Xu (ETH Zurich)*; Shuang Qiu (University of Chicago); Binhang Yuan (ETH Zurich); Jiawei Jiang (ETH Zurich); Cedric Renggli (ETH Zurich); Shaoduo Gan (ETH Zurich); Kaan Kara (ETHZ); Guoliang Li (Tsinghua University); Ji Liu (Kwai Inc.); Wentao Wu (Microsoft Research); Jieping Ye (Didi Chuxing & University of Michigan); Ce Zhang (ETH)
### 2021

Efficient Deep Learning Pipelines for Accurate Cost Estimations Over Large Scale Query Workload

VF^2Boost: Very Fast Vertical Federated Gradient Boosting for Cross-Enterprise Learning

ALG: Fast and Accurate Active Learning Framework for Graph Convolutional Networks

## VLDB

### 2023

Coresets over Multiple Tables for Feature-rich and Data-efficient Machine Learning

SHiFT: An Efficient, Flexible Search Engine for Transfer Learning

FastFlow: Accelerating Deep Learning Model Training with Smart Offloading of Input Data Pipeline

Galvatron: Efficient Transformer Training over Multiple GPUs Using Automatic Parallelism

### 2022

COMET: A Novel Memory-Efficient Deep Learning Training Framework by Using Error-Bounded Lossy Compression

Distributed Learning of Fully Connected Neural Networks using Independent Subnet Training

Optimizing Machine Learning Inference Queries with Correlative Proxy Models

Demonstration of Accelerating Machine Learning Inference Queries with Correlative Proxy Models

ByteGNN: Efficient Graph Neural Network Training at Large Scale

Hyper-Tune: Towards Efficient Hyper-parameter Tuning at Scale


### 2021

ParaX: Boosting Deep Learning for Big Data Analytics on Many-Core CPUs

Towards an Optimized GROUP BY Abstraction for Large-Scale Machine Learning



## ICDE

### 2022
PSP: Progressive Space Pruning for Efficient Graph Neural Architecture Search

TSplit: Fine-grained GPU Memory Management for Efficient DNN Training via Tensor Splitting

HybridGNN: Learning Hybrid Representation in Multiplex Heterogeneous Networks

Dynamic Model Tree for Interpretable Data Stream Learning

### 2021
An Efficient Approach for Cross-Silo Federated Learning to Rank

HuGE: An Entropy-driven Approach to Efficient and Scalable Graph Embeddings

Efficient Federated-Learning Model Debugging

