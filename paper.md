## SIGMOD 
### 2023

#### ST4ML: Machine Learning Oriented Spatio-Temporal Data Processing at Scale  
Kaiqi Liu (Nanyang Technological University)*; Panrong Tong (Alibaba Group); Mo Li (Nanyang Technological University); Yue Wu (Damo Academy, Alibaba Group); Jianqiang Huang (Alibaba Group)

#### FlexMoE: Scaling Large-scale Sparse Pre-trained Model Training via Dynamic Device Placement
Xiaonan Nie (Peking University)*; Xupeng Miao (Carnegie Mellon University); Zilong Wang (Microsoft); Zichao Yang (Carnegie Mellon University); Jilong Xue (Microsoft Research); Lingxiao Ma (Microsoft Research); Gang Cao (BAAI); Bin Cui (Peking University)

#### Automating and Optimizing Data-Centric What-If Analyses on Native Machine Learning Pipelines  
Stefan Grafberger (University of Amsterdam); Paul Groth (University of Amsterdam); Sebastian Schelter (University of Amsterdam);

#### GoodCore: Coreset Selection over Incomplete Data for Data-effective and Data-efficient Machine Learning  
Chengliang Chai (Beijing Institute of Technology); Jiabin Liu (Tsinghua University); Nan Tang (Qatar Computing Research Institute, HBKU); Ju Fan (Renmin University of China); dongjing miao (哈尔滨工业大学); Jiayi Wang (Tsinghua University); Yuyu Luo (Tsinghua University); Guoliang Li (Tsinghua University);

#### Scalable and Efficient Full-Graph GNN Training for Large Graphs  
Xinchen Wan (HKUST); Kaiqiang Xu (HKUST); Xudong Liao (HKUST); Yilun Jin (The Hong Kong University of Science and Technology); Kai Chen (HKUST); Xin Jin (Peking University);

#### EARLY: Efficient and Reliable Graph Neural Network for Dynamic Graphs  
Haoyang Li (The Hong Kong University of Science and Technology); Lei Chen (Hong Kong University of Science and Technology);

#### FEC: Efficient Deep Recommendation Model Training with Flexible Embedding Communication  
Kaihao Ma ( The Chinese University of Hong Kong); Xiao Yan (Southern University of Science and Technology)*; Zhenkun Cai (The Chinese University of Hong Kong); Yuzhen Huang (Meta); Yidi Wu (Meta Platforms, Inc); James Cheng (CUHK)

### 2022

#### Camel: Managing Data for Efficient Stream Learning  
Yiming Li (Hong Kong University of Science and Technology)*; Yanyan Shen (Shanghai Jiao Tong University); Lei Chen (Hong Kong University of Science and Technology)

#### In-Database Machine Learning with CorgiPile: Stochastic Gradient Descent without Full Data Shuffle  
Lijie Xu (ETH Zurich)*; Shuang Qiu (University of Chicago); Binhang Yuan (ETH Zurich); Jiawei Jiang (ETH Zurich); Cedric Renggli (ETH Zurich); Shaoduo Gan (ETH Zurich); Kaan Kara (ETHZ); Guoliang Li (Tsinghua University); Ji Liu (Kwai Inc.); Wentao Wu (Microsoft Research); Jieping Ye (Didi Chuxing & University of Michigan); Ce Zhang (ETH)
### 2021

Efficient Deep Learning Pipelines for Accurate Cost Estimations Over Large Scale Query Workload

VF^2Boost: Very Fast Vertical Federated Gradient Boosting for Cross-Enterprise Learning

ALG: Fast and Accurate Active Learning Framework for Graph Convolutional Networks

## VLDB

### 2023

Coresets over Multiple Tables for Feature-rich and Data-efficient Machine Learning

SHiFT: An Efficient, Flexible Search Engine for Transfer Learning

FastFlow: Accelerating Deep Learning Model Training with Smart Offloading of Input Data Pipeline

Galvatron: Efficient Transformer Training over Multiple GPUs Using Automatic Parallelism

### 2022

COMET: A Novel Memory-Efficient Deep Learning Training Framework by Using Error-Bounded Lossy Compression

Distributed Learning of Fully Connected Neural Networks using Independent Subnet Training

Optimizing Machine Learning Inference Queries with Correlative Proxy Models

Demonstration of Accelerating Machine Learning Inference Queries with Correlative Proxy Models

ByteGNN: Efficient Graph Neural Network Training at Large Scale

Hyper-Tune: Towards Efficient Hyper-parameter Tuning at Scale


### 2021

ParaX: Boosting Deep Learning for Big Data Analytics on Many-Core CPUs

Towards an Optimized GROUP BY Abstraction for Large-Scale Machine Learning



## ICDE

### 2022
PSP: Progressive Space Pruning for Efficient Graph Neural Architecture Search

TSplit: Fine-grained GPU Memory Management for Efficient DNN Training via Tensor Splitting

HybridGNN: Learning Hybrid Representation in Multiplex Heterogeneous Networks

Dynamic Model Tree for Interpretable Data Stream Learning

### 2021
An Efficient Approach for Cross-Silo Federated Learning to Rank

HuGE: An Entropy-driven Approach to Efficient and Scalable Graph Embeddings

Efficient Federated-Learning Model Debugging

